# Overview of Label Noise Processing in Natural Language Process
Repository For 《Overview of Label Noise Processing in Natural Language Process》

This repository contains links to relevant literature and dataset:

1.Under the folder \relatedLiterature, there are files related to literature reviews. The relevant links are as follows: 

| Survey                                                       | Link                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Impact of noisy labels in learning techniques: a survey**  | https://www.researchgate.net/publication/338347147_Impact_of_Noisy_Labels_in_Learning_Techniques_A_Survey |
| **A survey on deep learning with noisy labels: How to train your model when you cannot trust on the annotations?** | https://ieeexplore.ieee.org/abstract/document/9266015/       |
| **A survey of label-noise representation learning: Past, present and future** | https://arxiv.org/abs/2011.04406                             |
| **Image classification with deep learning in the presence of noisy labels: A survey** | https://www.sciencedirect.com/science/article/pii/S0950705121000344 |
| **A Survey of Methods for Detection and Correction of Noisy Labels in Time Series Data** | https://link.springer.com/chapter/10.1007/978-3-030-79150-6_38 |
| **Learning from noisy labels with deep neural networks: A survey** | https://ieeexplore.ieee.org/abstract/document/9729424        |
| **Review–a survey of learning from noisy labels**            | https://iopscience.iop.org/article/10.1149/2754-2726/ac75f5/meta |
| **The Robustness of Computer Vision Models against Common Corruptions: a Survey** | https://arxiv.org/abs/2305.06024                             |

2.Links to datasets:

| Dataset            | Link                                                         |
| ------------------ | ------------------------------------------------------------ |
| 20 newsgroup       | http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html |
| AG NEWS            | https://arxiv.org/pdf/1509.01626.pdf                         |
| Tacred             | https://nlp.stanford.edu/projects/tacred/                    |
| SemEval2010-Task 8 | https://semeval2.fbk.eu/semeval2.php?location=data           |
| CoNLL03            | https://arxiv.org/pdf/cs/0306050v1.pdf                       |
| OntoNotes5.0       | https://catalog.ldc.upenn.edu/LDC2013T19                     |
| IMDB               | https://ai.stanford.edu/~amaas/data/sentiment/               |
| SST-2              | https://gluebenchmark.com/                                   |
| DBpedia14          | https://huggingface.co/datasets/dbpedia_14                   |
| Yelp-2,Yelp-5      | https://www.yelp.com/dataset                                 |
| NYT10              | https://github.com/thunlp/OpenNRE/blob/master/benchmark/download_nyt10.sh |
| Wnut17             | https://huggingface.co/datasets/wnut_17                      |
| Wikiann            | https://huggingface.co/datasets/wikiann                      |
| Weibo NER          | https://gitcode.net/mirrors/hltcoe/golden-horse?utm_source=csdn_github_accelerato |
| TREC               | https://cogcomp.seas.upenn.edu/Data/QA/QC/                   |

3.Link to the evaluated method:

| Method                                                       | Link of the paper                                            | Link of the code                                             |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Westcoin: Weakly-supervised contextualized text classification with imbalance and noisy labels | https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9956110 | https://github.com/ypzhaang                                  |
| Label noise reduction in entity typing by heterogeneous partial label embedding | https://arxiv.org/pdf/1602.05307.pdf                         | https://github.com/INK-USC/PLE                               |
| Enhancing Robust Text Classification via Category Description | https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10027639 |                                                              |
| Distant Learning for Entity Linking with Automatic Noise Detection | https://arxiv.org/pdf/1905.07189.pdf                         | https://github.com/lephong/dl4el                             |
| Relabel the Noise: Joint Extraction of Entities and Relations via Cooperative Multiagents | https://arxiv.org/pdf/2004.09930.pdf                         |                                                              |
| Divide and Denoise: Learning from Noisy Labels in Fine-Grained Entity Typing with Cluster-Wise Loss Correction | https://aclanthology.org/2022.acl-long.141.pdf               | https://github.com/Los-Phoenix/NFETC-FCLC                    |
| SepLL: Separating Latent Class Labels from Weak Supervision Noise | https://arxiv.org/pdf/2210.13898.pdf                         | https://github.com/AndSt/sepll                               |
| Noisy Label Regularisation for Textual Regression            | https://aclanthology.org/2022.coling-1.371.pdf               | https://github.com/yuxiaw/Regularise-Regression-Noisy-Labels |
| Neighborhood-Regularized Self-Training for Learning with Few Labels | https://arxiv.org/pdf/2301.03726.pdf                         | https://github.com/ritaranx/NeST                             |
| Dimensionality-Driven Learning with Noisy Labels             | https://proceedings.mlr.press/v80/ma18d/ma18d.pdf            | https://github.com/xingjunm/dimensionality-driven-learning   |
| Learning from Noisy Labels with Coarse-to-Fine Sample Credibility Modeling | https://arxiv.org/pdf/2208.10683.pdf                         |                                                              |
| SaFER: A Robust and Efficient Framework for Fine-tuning BERT-based Classifier with Noisy Labels | https://aclanthology.org/2023.acl-industry.38.pdf            | https://github.com/ZheChi19/safer                            |
| SelfMix: Robust Learning Against Textual Label Noise with Self-Mixup Training | https://arxiv.org/pdf/2210.04525.pdf                         | https://github.com/noise-learning/SelfMix                    |
| Automatic Noisy Label Correction for Fine-Grained Entity Typing | https://arxiv.org/pdf/2205.03011.pdf                         | https://github.com/CCIIPLab/DenoiseFET                       |
| Towards Robustness to Label Noise in Text Classification via Noise Modeling | https://arxiv.org/pdf/2101.11214.pdf                         |                                                              |
| Robust Learning of Deep Predictive Models from Noisy and Imbalanced Software Engineering Datasets | https://web.archive.org/web/20230112142355id_/https://dl.acm.org/doi/pdf/10.1145/3551349.3556941 | https://github.com/RobustTrainer/RobustTrainer               |
| Noisy-Labeled NER with Confidence Estimation                 | https://arxiv.org/pdf/2104.04318.pdf                         | https://github.com/liukun95/Noisy-NER-Confidence-Estimation  |
| O2U-Net: A Simple Noisy Label Detection Approach for Deep Neural Networks | https://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_O2U-Net_A_Simple_Noisy_Label_Detection_Approach_for_Deep_Neural_ICCV_2019_paper.pdf |                                                              |
| LOPS: Learning Order Inspired Pseudo-Label Selection for Weakly Supervised Text Classification | https://arxiv.org/pdf/2205.12528.pdf                         | https://github.com/dheeraj7596/LOPS                          |
| STGN: an Implicit Regularization Method for Learning with Noisy Labels in Natural Language Processing | https://aclanthology.org/2022.emnlp-main.515.pdf             | https://github.com/tangminji/STGN-sst                        |
| Learning Named Entity Tagger using Domain-Specific Dictionary | https://arxiv.org/pdf/1809.03599.pdf                         | https://github.com/shangjingbo1226/AutoNER                   |
| Denoising Multi-Source Weak Supervision for Neural Text Classification | https://arxiv.org/pdf/2010.04582.pdf                         | https://github.com/weakrules/Denoise-multi-weak-sources      |
| Early-Learning Regularization Prevents Memorization of Noisy Labels | https://proceedings.neurips.cc/paper_files/paper/2020/file/ea89621bee7c88b2c5be6681c8ef4906-Paper.pdf | https://github.com/shengliu66/ELR                            |
| Learning to Denoise Distantly-Labeled Data for Entity Typing | https://arxiv.org/pdf/1905.01566.pdf                         | https://github.com/yasumasaonoe/DenoiseET                    |
| Learning with Noise: Improving Distantly-Supervised Fine-grained Entity Typing via Automatic Relabeling | https://www.ijcai.org/proceedings/2020/0527.pdf              |                                                              |
| ARNOR: Attention Regularization based Noise Reduction for Distant Supervision Relation Classification | https://aclanthology.org/P19-1135.pdf                        | https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2019-ARNOR |
| Named Entity Recognition via Noise Aware Training Mechanism with Data Filter | https://aclanthology.org/2021.findings-acl.423.pdf           | https://github.com/Huangxiusheng/Named-EntityRecognition-via-Noise-Aware-Training-Mechanism-withData-Filter |
| Context-based Virtual Adversarial Training for Text Classification with Noisy Labels | https://arxiv.org/pdf/2206.11851.pdf                         | https://github.com/domyounglee/baseline/tree/convat          |
| Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results | https://proceedings.neurips.cc/paper/2017/file/68053af2923e00204c3ca7c6a3150cf7-Paper.pdf |                                                              |
| Knowledge Distillation with Noisy Labels for Natural Language Understanding | https://arxiv.org/pdf/2109.10147.pdf                         |                                                              |
| Meta Self-Refinement for Robust Learning with Weak Supervision | https://arxiv.org/pdf/2205.07290.pdf                         | https://github.com/uds-lsv/msr                               |
| Contrast-Enhanced Semi-supervised Text Classification with Few Labels | https://ojs.aaai.org/index.php/AAAI/article/view/21391       |                                                              |
| BOND: BERT-Assisted Open-Domain Named Entity Recognition with Distant Supervision | https://arxiv.org/pdf/2006.15509.pdf                         | https://github.com/cliang1453/BOND                           |
| Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels | https://proceedings.neurips.cc/paper_files/paper/2018/file/a19744e268754fb0148b017647355b7b-Paper.pdf | https://github.com/bhanML/Co-teaching                        |
| Co-learning: Learning from Noisy Labels with Self-supervision | https://arxiv.org/pdf/2108.04063.pdf                         | https://github.com/chengtan9907/Co-learning-Learning-from-noisy-labels-with-self-supervision |
| How does Disagreement Help Generalization against Label Corruption? | https://proceedings.mlr.press/v97/yu19b/yu19b.pdf            |                                                              |
| Combating Noisy Labels by Agreement: A Joint Training Method with Co-Regularization | https://openaccess.thecvf.com/content_CVPR_2020/papers/Wei_Combating_Noisy_Labels_by_Agreement_A_Joint_Training_Method_with_CVPR_2020_paper.pdf |                                                              |
| Learning from Noisy Labels for Entity-Centric Information Extraction | https://arxiv.org/pdf/2104.08656.pdf                         | https://github.com/wzhouad/NLL-IE                            |
| DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling | https://arxiv.org/pdf/2305.19395.pdf                         | https://github.com/night-chen/DyGen                          |
| Local ensemble learning from imbalanced and noisy data for word sense disambiguation | https://www.sciencedirect.com/science/article/pii/S0031320317304351 |                                                              |
| Meta Label Correction for Noisy Label Learning               | https://ojs.aaai.org/index.php/AAAI/article/view/17319       | https://aka.ms/MLC                                           |
| Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels | https://proceedings.neurips.cc/paper_files/paper/2018/file/f2925f97bc13ad2852a7a551802feea0-Paper.pdf |                                                              |
| Noise-Robust Training with Dynamic Loss and Contrastive Learning for Distantly-Supervised Named Entity Recognition | https://aclanthology.org/2023.findings-acl.643.pdf           |                                                              |
| Symmetric Cross Entropy for Robust Learning with Noisy Labels | https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Symmetric_Cross_Entropy_for_Robust_Learning_With_Noisy_Labels_ICCV_2019_paper.pdf |                                                              |
| Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates | https://proceedings.mlr.press/v119/liu20e/liu20e.pdf         | https://github.com/gohsyi/PeerLoss                           |
| DiscrimLoss: A Universal Loss for Hard Samples and Incorrect Samples Discrimination | https://ieeexplore.ieee.org/abstract/document/10167857       | https://github.com/tangminji/DiscrimLoss                     |
| Learning with Noisy Labels                                   | https://proceedings.neurips.cc/paper_files/paper/2013/file/3871bd64012152bfb53fdf04b401193f-Paper.pdf |                                                              |
| TRAINING DEEP NEURAL NETWORKS ON NOISY LABELS WITH BOOTSTRAPPING | https://arxiv.org/pdf/1412.6596.pdf%EF%BC%89                 |                                                              |
| Learn with Noisy Data via Unsupervised Loss Correction for Weakly Supervised Reading Comprehension | https://aclanthology.org/2020.coling-main.236.pdf            |                                                              |
| LDMI: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise | https://proceedings.neurips.cc/paper/2019/file/8a1ee9f2b7abe6e88d1a479ab6a42c5e-Paper.pdf | https://github.com/Newbeeer/L_DMI                            |
| Instance-adaptive training with noise-robust losses against noisy labels | https://aclanthology.org/2021.emnlp-main.457.pdf             |                                                              |
| TRAINING CONVOLUTIONAL NETWORKS WITH NOISY LABELS            | https://arxiv.org/pdf/1406.2080.pdf                          |                                                              |
| TRAINING DEEP NEURAL-NETWORKS USING A NOISE ADAPTATION LAYER | https://www.nematilab.info/bmijc/assets/111821_paper.pdf     | https://github.com/udibr/noisy_labels                        |
| Making Deep Neural Networks Robust to Label Noise: a Loss Correction Approach | https://arxiv.org/pdf/1609.03683.pdf                         |                                                              |
| Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise | https://proceedings.neurips.cc/paper_files/paper/2018/file/ad554d8c3b06d6b97ee76a2448bd7913-Paper.pdf | https://github.com/mmazeika/glc                              |
| Are Anchor Points Really Indispensable in Label-Noise Learning? | https://proceedings.neurips.cc/paper_files/paper/2019/file/9308b0d6e5898366a4a986bc33f3d3e7-Paper.pdf |                                                              |
| Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning | https://proceedings.neurips.cc/paper/2020/file/512c5cad6c37edb98ae91c8a76c3a291-Paper.pdf |                                                              |
| A HOLISTIC VIEW OF LABEL NOISE TRANSITION MATRIX IN DEEP LEARNING AND BEYOND | https://openreview.net/pdf?id=aFzaXRImWE                     | https://github.com/pipilurj/ROBOT                            |
| Masking: A New Perspective of Noisy Supervision              | https://proceedings.neurips.cc/paper_files/paper/2018/file/aee92f16efd522b9326c25cc3237ac15-Paper.pdf | https://github.com/bhanML/Masking                            |
| Instance-Dependent Label-Noise Learning with Manifold-Regularized Transition Matrix Estimation | https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Instance-Dependent_Label-Noise_Learning_With_Manifold-Regularized_Transition_Matrix_Estimation_CVPR_2022_paper.pdf | https://github.com/Hao-Ning/MEIDTM-Instance-Dependent-Label-Noise-Learning-with-Manifold-Regularized-Transition-Matrix-Estimatio |
| Learning to Reweight Examples for Robust Deep Learning       | https://proceedings.mlr.press/v80/ren18a/ren18a.pdf          |                                                              |
| ADAPTIVE SELF-TRAINING FOR FEW-SHOT NEURAL SEQUENCE LABELING | https://arxiv.org/pdf/2010.03680.pdf                         |                                                              |
| Meta Self-training for Few-shot Neural Sequence Labeling     | https://dl.acm.org/doi/pdf/10.1145/3447548.3467235           | https://github.com/microsoft/MetaST/                         |
| Robust Self-Augmentation for Named Entity Recognition with Meta Reweighting | https://aclanthology.org/2022.naacl-main.297.pdf             | https://github.com/LindgeW/MetaAug4NER                       |
| Learning to Self-Train for Semi-Supervised Few-Shot Classification | https://proceedings.neurips.cc/paper_files/paper/2019/file/bf25356fd2a6e038f1a3a59c26687e80-Paper.pdf | github.com/xinzheli1217/learning-to-self-train               |
| Meta-Based Self-Training and Re-Weighting for Aspect-Based Sentiment Analysis | https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9870538 | www.computer.org/csdl                                        |
| Modeling Noisy Hierarchical Types in Fine-Grained Entity Typing: A Content-Based Weighting Approach | https://www.ijcai.org/Proceedings/2019/0731.pdf              | https://github.com/wujsAct/fine-grained-entity-typing-Hier-Denoise |
| Jointly Improving Language Understanding and Generation with Quality-Weighted Weak Supervision of Automatic Labeling | https://arxiv.org/pdf/2102.03551.pdf                         |                                                              |
| Fine-Tuning Pre-trained Language Model with Weak Supervision: A Contrastive-Regularized Self-Training Approach | https://arxiv.org/pdf/2010.07835.pdf?trk=public_post_comment-text | https://github.com/yueyu1030/COSINE                          |
